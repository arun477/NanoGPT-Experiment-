{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOw6mGaRsr3xyMTaW+/bXzQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arun477/NanoGPT-Experiment-/blob/main/nanoGPT_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TzH7I_51P63A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "id": "EzIoStWSqpBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69661b90-c445-4844-82b4-b41682255553"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f19ac4cfe50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frTAfXf554_f",
        "outputId": "4a50d671-0cfb-43f1-df41-984cf135657e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 05:35:08--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-02-09 05:35:09 (227 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "encode = lambda s: [stoi[i] for i in s]\n",
        "decode = lambda e: \"\".join([itos[i] for i in e])\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "mMJZvoxW56Cv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(len(data)* 0.9)\n",
        "train_data = data[:n] # 90% train data\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "FcibBkL89SNO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = 0.2\n",
        "block_size = 256 # max context length\n",
        "embd_dim = 384\n",
        "n_layer = 6\n",
        "num_heads = 6\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "learning_rate = 3e-4\n",
        "batch_size = 64\n",
        "eval_iters = 200\n",
        "max_iters = 5000\n",
        "eval_interval = 500"
      ],
      "metadata": {
        "id": "QgnWMNvhwXCQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sigle attention head\n",
        "class Head(nn.Module):\n",
        "  def __init__(self, embd_dim, head_size):\n",
        "    super().__init__()\n",
        "    self.query = nn.Linear(embd_dim, head_size, bias=False)\n",
        "    self.key = nn.Linear(embd_dim, head_size, bias=False)\n",
        "    self.val = nn.Linear(embd_dim, head_size, bias=False)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    q = self.query(x) # (B, T, head_size)\n",
        "    k = self.key(x) # (B, T, head_size)\n",
        "    v = self.val(x) # (B, T, head_size)\n",
        "    wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, T)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, T, T)\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    wei = self.dropout(wei) # (B, T, T)\n",
        "    out = wei @ v # (B, T, head_size)\n",
        "    return out"
      ],
      "metadata": {
        "id": "SCgpT1RKwGHc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mulit head attention (just a compose of single head attention)\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embd_dim, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(embd_dim, head_size) for _ in range(num_heads)])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.proj = nn.Linear(embd_dim, embd_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = [h(x) for h in self.heads]\n",
        "    out = torch.cat(out, dim=-1)\n",
        "    out = self.proj(out)\n",
        "    out = self.dropout(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "Xt9BUgjZzBNs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, embd_dim):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embd_dim, 4*embd_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*embd_dim, embd_dim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "fpIPreZr1AEY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, embd_dim, num_heads):\n",
        "    super().__init__()\n",
        "    head_size = embd_dim // num_heads\n",
        "    self.sa = MultiHeadAttention(embd_dim, num_heads, head_size)\n",
        "    self.fw = FeedForward(embd_dim)\n",
        "    self.ln1 = nn.LayerNorm(embd_dim)\n",
        "    self.ln2 = nn.LayerNorm(embd_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.fw(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "l8trKSWE11R7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramModel(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, embd_dim)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, embd_dim)\n",
        "    self.blocks = nn.Sequential(*[Block(embd_dim, num_heads) for _ in range(n_layer)])\n",
        "    self.lf = nn.LayerNorm(embd_dim)\n",
        "    self.lm_head = nn.Linear(embd_dim, vocab_size)\n",
        "\n",
        "  def forward(self, idx, target=None):\n",
        "    B, T = idx.shape\n",
        "\n",
        "    token_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "    x = token_emb + pos_emb\n",
        "    x = self.blocks(x)\n",
        "    x = self.lf(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if target is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      target = target.view(B*T)\n",
        "      loss = F.cross_entropy(logits, target)\n",
        "    \n",
        "    return loss, logits"
      ],
      "metadata": {
        "id": "OvqOVW743LsK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramModel()\n",
        "m = model.to(device)"
      ],
      "metadata": {
        "id": "vD5rSO105ZOt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_params = sum(ele.numel() for ele in m.parameters())/1e6\n",
        "print(n_params, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx7ply8m8MO-",
        "outputId": "503f556c-e823-4676-c8d3-d757def8c687"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.788929 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "elWg9FKO8YrU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "  data = train_data if split=='train' else val_data\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "SVd1jJts9GOK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      loss, logits = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "jSSgrGXd-OiT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "  if iter % eval_interval == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "  loss, logits = model(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xrK6ACn_JfB",
        "outputId": "5cefc1ed-929d-4d7a-c927-c964872be23b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.2853, val loss 4.2827\n",
            "step 500: train loss 2.0071, val loss 2.0987\n",
            "step 1000: train loss 1.5960, val loss 1.7798\n",
            "step 1500: train loss 1.4354, val loss 1.6408\n",
            "step 2000: train loss 1.3449, val loss 1.5751\n",
            "step 2500: train loss 1.2737, val loss 1.5286\n",
            "step 3000: train loss 1.2215, val loss 1.4994\n",
            "step 3500: train loss 1.1806, val loss 1.4788\n",
            "step 4000: train loss 1.1418, val loss 1.4819\n",
            "step 4500: train loss 1.1053, val loss 1.4795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(idx, max_new_tokens):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -block_size:] # crop idx to the block_size tokens\n",
        "    loss, logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "pJNyjNDU_78M"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(generate(context, max_new_tokens=10000)[0].tolist()))"
      ],
      "metadata": {
        "id": "lWdKW5qDDQk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bc224d-345a-491c-adcc-5e8a28263f24"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PETER:\n",
            "And a rung, seek you to sanctuit on him\n",
            "What our valriage; there best brief it persortly,\n",
            "Some blessed were like you hew 'twixt his king.'\n",
            "The head of her, shall London, you find him you there.\n",
            "\n",
            "GLOUCESTER:\n",
            "She hath tongues thy aexions to do everwean those\n",
            "A carved conceal a hazant to bear me,\n",
            "And so a that you: hear him it be so,\n",
            "As Abhoridal may far your fall,\n",
            "As laster, that forgives you with she spit!\n",
            "\n",
            "LADY CAPULET:\n",
            "The prince of allow wings.\n",
            "\n",
            "ROMEO:\n",
            "What is it good?\n",
            "\n",
            "PAULIXENES:\n",
            "Mine, patient us night; and roused me,\n",
            "So much passion our bodies are cat asleep,\n",
            "Where is noble arms by thus.\n",
            "\n",
            "VIRGILIA:\n",
            "And say the envity I prate thinks his renown'd\n",
            "Cry by me to the head; And for unbeing clot\n",
            "Is no store was entertainted to me.\n",
            "\n",
            "VOLUMNIA:\n",
            "Saw you so.\n",
            "\n",
            "POLIXENES:\n",
            "Give me this soil; 'tis ta'en and wherein; like the\n",
            "open her, her if mercy, we longe on you, good nor with some:\n",
            "\n",
            "VISCALUS:\n",
            "Ay, you shall go and swears it his far.\n",
            "\n",
            "ESCALUS:\n",
            "Yon are asked with further.\n",
            "\n",
            "First Lord:\n",
            "I may solate him: he has knew his protess sound\n",
            "When he well till he stands thus too.\n",
            "\n",
            "Rome:\n",
            "As she were he here, obey'd--advised him:\n",
            "And so, and too much at at thou a meat soil a\n",
            "lie.\n",
            "\n",
            "ESCALUS:\n",
            "At what is true the world an?\n",
            "\n",
            "Second Murderer:\n",
            "Play now, he changing i' the tewk; good sir, and forbeauty,\n",
            "Makes me to seen a bettding one at things spill.\n",
            "\n",
            "Second Murderer:\n",
            "May it no remedy rescue away\n",
            "Thou heard'st a gentle?\n",
            "\n",
            "First Messenger:\n",
            "By his husband is weak from its.\n",
            "\n",
            "LUCOSTER:\n",
            "Volsce, deparate in,\n",
            "Gentlements and her lawless and king.\n",
            "\n",
            "KING RICHARD II:\n",
            "We may stain speak unfursents: to speak me.\n",
            "\n",
            "LOD ROSS:\n",
            "Thus, by Caesal, Pompet! Depopulture-vow; adventured\n",
            "With sorrow an upress'd sword, royal ot slain\n",
            "That letter'd Warwick takern hand so the food\n",
            "And to five them, ears remortable royal la\n",
            "His toldy it! Mowbray it, if that they say,\n",
            "\n",
            "Seventence to Sufford Angelo, to stand you with.\n",
            "\n",
            "OXFORD:\n",
            "And is it until Happingment;\n",
            "And one to make a fade think and by their Anthuman;\n",
            "Menening wooly and mean aside their people.\n",
            "\n",
            "CORIOLANUS:\n",
            "Were setuted in the Volsces: set do\n",
            "Of saily blessed that Romans, they sich\n",
            "had theirs one with persons of your strength,\n",
            "And, in of my awhile, since he he she,\n",
            "He spent not crass to give your gives.\n",
            "\n",
            "VOLUMNIA:\n",
            "He will serves this press'd for'ence the fire\n",
            "That took your stands to lay for your master,\n",
            "And smilings Richard where you to each in her maid,\n",
            "Whereof, brought a bloody it as\n",
            "A lips out to the jeies of our work, our blood is loss'd.\n",
            "\n",
            "VIS:\n",
            "Mean's nature, I empty o'er thy wold, again thee\n",
            "Will deliver'd out with our world.\n",
            "\n",
            "BENVOLIO:\n",
            "Why 'heard it in being forces?\n",
            "\n",
            "ROMEO:\n",
            "Why, so will you rather keys and wonderly pity?\n",
            "Made fast off that why spirit to the meets,\n",
            "Nor tale things must enough the base of virgin:\n",
            "Tushy, fresolved me with dead-pleasing steel,\n",
            "And the heaven aem'd their follishing on their.\n",
            "\n",
            "ROMEO:\n",
            "What comforting\n",
            "Then being the sentence to keep it, but he,\n",
            "Yet shall ught but rest it the need testendant.\n",
            "And tell how me not, liberty me,\n",
            "As I that soon sycratch it, it own, my fancience?\n",
            "Wherefore the lord as a traitor light,\n",
            "And all is ceremonwealth from their a cape,\n",
            "Bearing coward their sons, vault waters.\n",
            "\n",
            "JULIET:\n",
            "Ay, why so patient?\n",
            "\n",
            "BRAKENBURY:\n",
            "Have you to desert.\n",
            "\n",
            "BRINCA:\n",
            "Tribunes do but myself to Lord Salisbury;\n",
            "That my reson is as great cloier enough breath\n",
            "'For a gross unto this man nothing thoriving.'\n",
            "South of thy hand of done to be ilunge\n",
            "With shame to be brother'd austom'd by:\n",
            "One of Tyral, doth sooner too think\n",
            "As if thee usoan not by your your stain,\n",
            "A cousin and your son, but ones, so hangry\n",
            "To-morrow babout your both us.\n",
            "\n",
            "ANGELO:\n",
            "Did more me of your tent, and heart me to your prisoner.\n",
            "\n",
            "GLOUCESTER:\n",
            "Away!\n",
            "\n",
            "PRINCE Edward:\n",
            "What, then? mark you to his men spysiegr.\n",
            "\n",
            "BUCKINGHAM:\n",
            "If they be, they lies then, cats and stands.\n",
            "Were you no tied of a promise,\n",
            "That of myself will capt with delights obed!\n",
            "Let you merrinant, I pray a wit.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Let me go with you so: I do not speak.\n",
            "\n",
            "Provost:\n",
            "If is your within beholding your dries;\n",
            "And you saw 'twill make his as youth:\n",
            "Has words light, let us in justice,\n",
            "If you'ld will persuade a pity fear of you; long\n",
            "At me fortune servent\n",
            "To talk of doubleture, to him, if can last,\n",
            "And then do me your unlike breasts. BeseIt,\n",
            "We'll reap with some Tullus' bones: 'twere not Romeo,\n",
            "For her you in her honour infants, here he die.\n",
            "\n",
            "HASTINGS:\n",
            "Vevernius, my liege my Pla, Pembra; who is your made\n",
            "Ef some blessed or general conjoy.\n",
            "\n",
            "GLOUCESTER:\n",
            "Direct most get without me; or the thing of many\n",
            "Thy power to convening and your voices back.\n",
            "\n",
            "KING HENRY VI:\n",
            "Then innointer is mossipparts murded to Margaret.\n",
            "\n",
            "NORTHUMBERLANCE:\n",
            "\n",
            "LADY ANNE:\n",
            "Good night, yond mortaling through the Richard,\n",
            "But yet lie to my serving to a king,\n",
            "In minder, so I should up enjoy\n",
            "A: mine entreatience of a mine eites!\n",
            "Go, pend chains to the sea-heaved event,\n",
            "Forgive times, was hedged fond for none and and dept\n",
            "Against to the signable and between's sun warm.\n",
            "\n",
            "KING RICHARD II:\n",
            "Cold farewell: but prove to thy trage indept.\n",
            "\n",
            "STANLEY:\n",
            "So many hability: natural nenive!\n",
            "\n",
            "KING RICHARD III:\n",
            "What you have speech two motimes\n",
            "That breathe I was in that three--\n",
            "\n",
            "First Keeper:\n",
            "Revolve: very lipt,\n",
            "Give with me no do weep my crown than cross;\n",
            "And thou shalt call thee neck abate\n",
            "To purse to asite the light: but heaven shall not at\n",
            "Edward heel doubt, and saffright this song-good male!\n",
            "\n",
            "BAGOT:\n",
            "My must hath argabed, besting: how thisk, he,\n",
            "Forse, when an half still amportide, a perfection\n",
            "Would answer as I seen ungoodly cribe,\n",
            "You mean to beas to die our entiretiment:\n",
            "But what is your high gracious princely has bed;\n",
            "Sho will chook to a suffer, I speak to brank,\n",
            "To or their so proffit hand, by: for't myself,\n",
            "Be withoutd with me to you appriece. Heaven him!\n",
            "Hadst thou been a sea\n",
            "For Polixenes, honour, master, which would,\n",
            "What, like to thy human, when vault you, had made a most.\n",
            "\n",
            "BRAKENBURY:\n",
            "The state, stir, do your knove; and saint fit!\n",
            "\n",
            "BAKINGHENRY:\n",
            "In sweet doubt-stericked, that heavens\n",
            "When chanced he takes her bawdy at our nature,\n",
            "And to what Richmond is the time: I hate myself,\n",
            "Lead me in suffer: the rack would too much\n",
            "Hath seem'd you perform'd his supple story.\n",
            "\n",
            "BARNARDINE:\n",
            "O, cherse\n",
            "I semitting his officious foul thoughts! Their eyes':\n",
            "Rather that name I live his doubt\n",
            "With two. Good piting happy him, you in probat,\n",
            "As to some wound spurs; not unparlel,\n",
            "Were suffiring from his liking his lineague,\n",
            "As if held, in shorm of fast so pitch\n",
            "Within your sling, gassing, power your holy abses.\n",
            "My horse time, would I must be king to thee.\n",
            "That dear me, I love me sun my castlenge forth\n",
            "In this disgraces and my child this fontune's eye:\n",
            "And sehe is the world, thou kilp'st together,\n",
            "My boy this fable breathe family seen:\n",
            "And so being loast to your bissoke three;\n",
            "Let first thy grave, one tending to anoon.\n",
            "\n",
            "GLOUCESTER:\n",
            "Then, mighty while then my behalf\n",
            "To thee that garl, madace: bewhich Henry 'O, 'tis it part serve\n",
            "With my powers: that's for it.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Well so here died?\n",
            "\n",
            "BUCKINKINGHAM:\n",
            "Here's gone his camp to those that vows,\n",
            "And to shortlener of a dream.\n",
            "Mighty singing liety bone: I'll be slain my househadS:\n",
            "But but fond, twenty tongue, 'twere you, be it gone.\n",
            "\n",
            "KING RICHARD III:\n",
            "Hear slander to this lament;\n",
            "Now Henry's affair to him your leave sound;\n",
            "Which Volsces to the armour's sons, for whilesome\n",
            "His present try voiceed branished king,\n",
            "Nor slowled with discreet bounted in my device,\n",
            "And in act watern to the flowers of grief,\n",
            "But line live and that ha, which dead largumpt,\n",
            "And when have for some as thine evils,\n",
            "As lack'd awaywed were a wit picket,\n",
            "And may loved, some evire statued;\n",
            "Cown banish'd known thus; fake and fain arts\n",
            "Will as fall o' blood redreaments,' if a thought:\n",
            "Princes the writ, I knew thee hoped to some up,\n",
            "To do this wive an evenge of his king;\n",
            "But not of unseverhold debt-day.\n",
            "\n",
            "DUKE OXf ISCAS:\n",
            "Amen.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Nothing;\n",
            "Is the dust before thinking preventure: still we bitteth\n",
            "how doth us yet.\n",
            "\n",
            "INGELO:\n",
            "Woe--good me: think you'ld even do lest to make you:\n",
            "This words off light in aboard to the sea\n",
            "With hand little intelligent. Come, of your plagues short;\n",
            "You were to sead compation and sympethions\n",
            "Either from your first not goes, when call upon'st yourselves:\n",
            "Hour bay wrong: and I famiss, myself, knows myself\n",
            "Hereafter, or how me advantage with you,\n",
            "I will recremend because; and with bound me\n",
            "The senate world of all.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "If twirds, then hand when he will taken him good\n",
            "And punishes him out him, which he is discrified,\n",
            "The raged positicy of the dove's deed reble,\n",
            "And there will in his strange subject,\n",
            "And virtuous shall beaf the rescue.\n",
            "Come, slay nothy; for their beck again,\n",
            "And that them to him known the hee; for less, they say thence Juliet.\n",
            "\n",
            "LAONT:\n",
            "Apollo, my lord!\n",
            "\n",
            "Clown:\n",
            "Tranio, swift it to the feign palous of me.\n",
            "Claudion Bolingbroke.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "O, Good Camule ElsSTEy, and there my husband of kings.\n",
            "\n",
            "DUKE OF RUCH:\n",
            "\n",
            "HENRY BOLIZAND:\n",
            "So that I spoke at knand for prisoner than he in.\n",
            "Your known standsle, or now one altaying:\n",
            "The king now many thereon my heart\n",
            "That will gall but fourtees into and us: as so\n",
            "Of covertains the coronable, and ones.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Hast thou, fool, or aught, thou art king King,\n",
            "Prob and our requetion your highness nothing:\n",
            "Thou thus high thy father bed my louths to have head,\n",
            "His younges hate, and opprojies to use,\n",
            "Why should mine own as false return in:\n",
            "It do befend, I have to persume,\n",
            "To London on the Duke of Henry,\n",
            "And expassion of Englant most subject milk,\n",
            "As is dishonour Claughance to your grace.\n",
            "Is Allas? I say that firry is not sworn,\n",
            "More them, may be open the peoples, they usply.\n",
            "\n",
            "FLORIZEL:\n",
            "How, my good shadow fast words? why would have I respented?\n",
            "\n",
            "CAPULET:\n",
            "What, noble You.\n",
            "\n",
            "WARWICK:\n",
            "If Hence, heaven! neven hope greatness!\n",
            "You have no ppolicy: Abho you, Lamy cers comes:\n",
            "Master unseen your England.\n",
            "\n",
            "OXFORD:\n",
            "Farewell;\n",
            "Then, if tears not of remembers to me quiet:\n",
            "Unless you do might to do affecting this.\n",
            "But what he is a happy tep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open('generated_output.txt', 'w').write(decode(generate(context, max_new_tokens=10000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7poslqsHm9Z",
        "outputId": "b1464e4e-02ca-4108-b1c8-0ab7fd096940"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10001"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHTgKy4c4uwo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}